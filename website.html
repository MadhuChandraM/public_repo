<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Body Movement Detection</title>
  <style>
    /* Styling for the webpage */
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      background-color: #f4f4f9;
    }

    #video {
      border: 2px solid black;
      margin-top: 20px;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 1;
    }
  </style>
</head>
<body>

  <h1>Body Movement Detection via Webcam</h1>

  <p>Allow access to your webcam for detecting body movements.</p>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" width="640" height="480"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>

  <script>
    // Access webcam stream
    async function setupCamera() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true
      });

      video.srcObject = stream;
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve(video);
        };
      });
    }

    // Load PoseNet model
    async function loadPoseNet() {
      const net = await posenet.load();
      return net;
    }

    // Detect poses from the video stream
    async function detectPose(net) {
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');

      const pose = await net.estimateSinglePose(video, {
        flipHorizontal: false
      });

      // Clear the canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Draw keypoints
      pose.keypoints.forEach(point => {
        if (point.score > 0.5) {
          ctx.beginPath();
          ctx.arc(point.position.x, point.position.y, 5, 0, 2 * Math.PI);
          ctx.fillStyle = 'aqua';
          ctx.fill();
        }
      });

      // Optionally, draw skeleton lines between keypoints
      const adjacentKeyPoints = posenet.getAdjacentKeyPoints(pose.keypoints, 0.5);
      adjacentKeyPoints.forEach(([from, to]) => {
        ctx.beginPath();
        ctx.moveTo(from.position.x, from.position.y);
        ctx.lineTo(to.position.x, to.position.y);
        ctx.strokeStyle = 'aqua';
        ctx.lineWidth = 2;
        ctx.stroke();
      });

      // Call again for the next frame
      requestAnimationFrame(() => detectPose(net));
    }

    // Initialize everything
    async function init() {
      const video = await setupCamera();
      const net = await loadPoseNet();
      detectPose(net);
    }

    // Start the process
    init();
  </script>
</body>
</html>
